<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>


<script>
    MathJax = {
        chtml: {
            scale: 0.8
        }
    };
</script>
<script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>


<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-size:32px;
        font-weight:300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
        5px 5px 0 0px #fff, /* The second layer */
        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
        10px 10px 0 0px #fff, /* The third layer */
        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
        15px 15px 0 0px #fff, /* The fourth layer */
        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
        20px 20px 0 0px #fff, /* The fifth layer */
        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
        25px 25px 0 0px #fff, /* The fifth layer */
        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }

    .paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
        5px 5px 0 0px #fff, /* The second layer */
        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
        10px 10px 0 0px #fff, /* The third layer */
        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
<head>
    <title>RegBN</title>
    <meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
    <meta property="og:title" content="Creative and Descriptive Paper Title." />
    <meta property="og:description" content="Paper description." />

    <!-- Get from Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src=""></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-75863369-6');
    </script>
</head>

<body>
<br>
    <center>
        <span style="font-size:36px">RegBN: Batch Normalization of Multimodal Data  with <br>  Regularization</span>
        <table align=center width=600px>
            <table align=center width=600px>
                <tr>
                    <br>
                    <td align=center width=100px>
                        <center>
                            <span style="font-size:24px"><a href="https://github.com/mogvision">Morteza Ghahremani</a></span>
                        </center>
                    </td>
                    <td align=center width=100px>
                        <center>
                            <span style="font-size:24px"><a href="https://www.professoren.tum.de/en/wachinger-christian">Christian Wachinger</a></span>
                        </center>
                    </td>
                </tr>
            </table>
        </table>
        <br>
        <span style="font-size:22px"> Technical University of Munich (TUM), Germany</span>
        <br>
        <br>
        </table>
            <table align=center width=320px>
                <tr>
                    <td align=center width=340px>
                        <center>
                            <span style="font-size:24px"><a href="https://arxiv.org/abs/2310.00641">[Paper & Supplementary]</a></span>
                        </center>
                    </td>
                    <td align=center width=180px>
                        <center>
                            <span style="font-size:24px"><a href='https://github.com/mogvision/regbn'>[Code]</a></span><br>
                        </center>
                    </td>

                </tr>
            </table>
        </table>



    </center>

    <br>

    <br>

    <br>

    <center>
        <table align=center width=850px>
            <tr>
                <td width=230px>
                    <center>
                        <img class="round" style="width:900px" src="./framework.png"/>
                    </center>
                </td>
            </tr>
        </table>
    </center>

    <hr>

    <table align=center width=850px>
        <center><h1>Abstract</h1></center>
        <tr>
            <td>
                This paper introduces a novel approach for the normalization of multimodal data, called RegBN, that incorporates regularization. 
                RegBN uses the Frobenius norm as a regularizer term to address the side effects of confounders and underlying 
                dependencies among different data sources.  It enables effective normalization of both low and high-level features in multimodal neural networks.

                <ul>
                    <li>RegBN is batch normalisation method for <b> multimodal data</b> </li>

                    <li>RegBN generalizes well across multiple modalities of any
                        architecture such MLPs, CNNs, ViTs, etc</li>
                    <br>
                    <li>RegBN can be applied to a vast array of heterogeneous data types,
                        including text, audio, image, video, depth, tabular, 3D MRI, etc</li>
                    <br>
                    <li>RegBN eliminates the need for learnable parameters, simplifying training and inference</li>
                  </ul>
            </td>
        </tr>
    </table>
    <br>

    <hr>

    <table align=center width=960px>
        <center><h1>Method</h1></center>
        <tr>
            <td>
                Given a trainable multimodal neural network (e.g., MLPs, CNNs, ViTs) with multimodality 
                backbones \(A\) and \(B\). 

                Let \(f^{(l)}\) represent the \(l\)-th layer of network \(A\)  
                with batch size \(b\) and \(n_1\times...\times n_N\) 
                features that are flattened into a vector of size \(n\).  
                In a similar vein, we define \(g^{(k)}\) as the \(k\)-th layer of 
                network \(B\) with \(m_1\times\ldots\times m_M\) features that are flattened into a vector of size \(m\). 
                RegBN make \(f^{(l)}\) and \(g^{(k)}\) mutually independent via

                $$F(W^{(l,k)},\lambda_{+}) = ||{f^{(l)}-W^{(l,k)} g^{(k)}}||^2_2+\lambda_{+} (||{W^{(l,k)}}||_F-1)$$

                Where \(W^{(l,k)}\) is a projection matrix of size \(n\times m\) and 
                \({\lambda}_{+}\) is a Lagrangian multiplier. 
                \(W^{(l,k)}\) and \({\lambda}_{+}\) are estimated via an innovative recursive-based algorithm.
                
            
                <h3>Where is it advisable to apply RegBN?</h3>

        <table>
            <center>
                <img class="round" style="width:425px" src="./layer.png">
                <img class="round" style="width:400px" src="./late.png"/>
                <br>
                <center>
                    (a) RegBN as a layer normalizer
                    &nbsp; &nbsp; &nbsp;
                    &nbsp; &nbsp;  &nbsp;
                    (b) Late fusion with RegBN
                </center>

                <br>
                <img class="round" style="width:400px" src="./mid.png"/>
                <img class="round" style="width:400px" src="./early.png"/>
                <center>
                    (c)  Layer fusion (LF) with RegBN
                    &nbsp; &nbsp; &nbsp;
                    &nbsp; &nbsp;  &nbsp;
                    (d) Early fusion with RegBN
                </center>
            </center>

        </table>
            </td>
        </tr>

    </table>
    <br>
    <hr>
    <table align=center width=850px>
        <center><h1>Experiments</h1></center>
        <tr>
            <td>
                In the paper, we reported the performance of RegBN over eight multimodal databases with various modalities, 
                including <b>multimedia</b>, <b>affective computing</b>, 
                <b>robotics</b>, <b>healthcare diagnosis</b>, etc.
            </td>
        </tr>

    </table>


    <br>
    <br>

    <table align=center width=850px>
        <tr>
            <td>
               <b>MNIST</b> 

        <table>
            <center>
                <img class="round" style="width:800px" src="./mnist.png"/>
            </center>
        </table>
            <center>
                tSNE visualization of the features extracted from a-b) an unimodal image and an unimodal
                audio, and c-e) the multimodal model with different normalization methods. Each data point
                represents a sample
            </center>
            </td>
        </tr>

    </table>

    <br>
    <br>

    <table align=center width=850px>
        <tr>
            <td>
               <b>Multimedia (MM-IMDb)</b> 
               <br>
        <table>
            <center>
                <img class="round" style="width:600px" src="./mmimdb.png"/>
            </center>
        </table>
            <center>
                Multi-label classification scores (F1 score) of baseline 
                <span style="font-size:16px"><a href="https://github.com/mengmenm/SMIL">SMIL</a></span> 
                with/without normalization on the   
                <span style="font-size:16px"><a href="https://arxiv.org/pdf/1702.01992.pdf">MM-IMDb</a></span> dataset
            </center>
            </td>
        </tr>

    </table>

    <br>

    More results and details can be found in the paper and its supplementary. 
    



    <br>

    <hr>


    <table align=center width=450px>
        <tr>
        <center><h1>BibTeX</h1></center>
            <left>
                <pre style="background-color:lightgray;"><code>
            @article{ghahremani2023regbn,
                  title={RegBN: Batch Normalization of Multimodal Data with Regularization},
                  author={Ghahremani, Morteza and Wachinger, Christian},
                  year={2023},
                  eprint={2310.00641},
                  archivePrefix={arXiv},
                  primaryClass={cs.CV}
            }
             </code></pre>
        </left>
        </tr>
    </table>


    <br>

    <hr>
    <br>

    <table align=center width=900px>
        <tr>
            <td width=400px>
                <left>
                    <center><h1>Acknowledgments</h1></center>
                    This project was founded by <a href="https://mcml.ai/"> Munich Center for Machine Learning: MCML.
                </left>
            </td>
        </tr>
    </table>

<br>
</body>
</html>
